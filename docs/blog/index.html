<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="$\partial$P is Easy with Flux # Flux has taken some major strides in the past couple of years since it has been out. But its verstality can be subtle to grasp wothout actually using it. So this series is for bringing to notice how best to take advantage of Flux and its gradient-taking backend (automatic differentiation: AD for short) Zygote.
Starting with a bit of housekeeping. This piece will introduce some basic guidelines to Julia programming and should hopefully help with your understanding of the language and using it with a few neat tricks."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Differentiable Programming is Easy with Flux"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://dhairyalgandhi.github.io/docs/blog/"><title>Differentiable Programming is Easy with Flux |</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.95d69eb6bad8b9707ff2b5d8d9e31ce70a1b84f2ed7ffaf665ffcf00aa7993bd.css integrity="sha256-ldaetrrYuXB/8rXY2eMc5wobhPLtf/r2Zf/PAKp5k70=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.362346d5769e5b61a99f9bc35ce5e17ed21e4f3dad13452ed3bf8050417c8369.js integrity="sha256-NiNG1XaeW2Gpn5vDXOXhftIeTz2tE0Uu07+AUEF8g2k=" crossorigin=anonymous></script>
<link rel=alternate type=application/rss+xml href=https://dhairyalgandhi.github.io/docs/blog/index.xml title></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span></span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=https://dhairyalgandhi.github.io/docs/blog/ class=active>Differentiable Programming is Easy with Flux</a><ul></ul></li><li><a href=https://dhairyalgandhi.github.io/docs/layer/>Writing Custom Layers with Flux</a><ul></ul></li></ul><a href=https://wandb.ai/dhairyalgandhi/DDP_Trantor/reports/Data-Parallel-Training-with-Flux-jl--VmlldzoxNTA0Mjk5>Distributed Data Parallel Training in Julia</a><br><a href=mailto:dhairyagandhi96@gmail.com><img src=https://img.icons8.com/material-sharp/30/000000/mail.png title="dhairyagandhi96 [AT] gmail.com"></a>
<a href=https://github.com/DhairyaLGandhi><img src=https://img.icons8.com/material-rounded/30/000000/github.png></a>
<a href="https://scholar.google.com/citations?hl=en&user=9i0Z2xkAAAAJ"><img src=https://img.icons8.com/ios-glyphs/30/000000/graduation-cap--v1.png></a></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Differentiable Programming is Easy with Flux</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#how-the-adjoints-are-defined>How the adjoints are defined</a></li><li><a href=#a-basic-optimisation-loop>A Basic Optimisation Loop</a></li><li><a href=#adapting-this-to-a-custom-type>Adapting this to a custom type</a></li><li><a href=#optimising-colours>Optimising Colours</a></li></ul></nav></aside></header><article class=markdown><h1 id=partialp-is-easy-with-flux>$\partial$P is Easy with Flux
<a class=anchor href=#partialp-is-easy-with-flux>#</a></h1><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><p>Flux has taken some major strides in the past couple of years since it has been out. But its verstality can be subtle to grasp wothout actually using it. So this series is for bringing to notice how best to take advantage of Flux and its gradient-taking backend (automatic differentiation: AD for short) Zygote.</p><p><img src=https://raw.githubusercontent.com/FluxML/fluxml.github.io/master/logo.png alt=flux-logo></p><p>Starting with a bit of housekeeping. This piece will introduce some basic guidelines to Julia programming and should hopefully help with your understanding of the language and using it with a few neat tricks. Another task is to clarify what Flux and its ecosystem isn&rsquo;t. It <strong>isn&rsquo;t a strictly deep learning library</strong>, although it does have most of the primitives for deep learning defined. It is essentially a framework for differentiable programming.</p><p>For a TL;DR, differentiable programming ($\partial$P) is a way of treating arbitrary programs as differentiable. Put it easily, it is a generalisation of the way we treat deep learning as consisting of a forward pass and a backwards pass. It applies the chain rule (refer the equation below) to every operatoin that takes place in a program. The record and sequence of the operations to every element in the code is the code itself! Specifically, it is the AST of the code.</p><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script>
<script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>
\($$ \frac{ d{ (f \circ g)(x) }}{ d{x}} = \frac{\partial f}{\partial g} \times \frac{\partial g}{\partial x} $$\)</span><p>It replaces the standard neural network, with basically any other code and the model subtly melts away from being a sigular entity (think <em>Sequential</em> from Keras), to a part of general logic that you wish to implement. ~The adjoints are defined just as they are for any other differentiable function, again generalised from the mathematical priciples, to implementing logic consistent with what a deconstruction of the actions would look like.~</p><h2 id=how-the-adjoints-are-defined>How the adjoints are defined
<a class=anchor href=#how-the-adjoints-are-defined>#</a></h2><p>Consider a regular function</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#66d9ef>function</span> f(arg1<span style=color:#f92672>::</span><span style=color:#66d9ef>CustomType</span>, arg2, arg3<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>  transform1 <span style=color:#f92672>=</span> f1(arg1)
</span></span><span style=display:flex><span>  transform2 <span style=color:#f92672>=</span> f2(transform1, arg3<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>  result <span style=color:#f92672>=</span> f3(transform1, transform2)
</span></span><span style=display:flex><span>  result
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span><span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># going down in the abstraction</span>
</span></span><span style=display:flex><span><span style=color:#f92672>.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>function</span> f1(arg)
</span></span><span style=display:flex><span>  result <span style=color:#f92672>=</span> operations_with_some_concrete_types(arg)
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span></code></pre></div><p>The function <code>f</code> can accept arguments with any type, including user defined ones. When we call on this function, it executes a bevy of other functions, ultimately ending with some basic operations involving concrete types (be they Arrays, Numbers, Symbols, etc), let&rsquo;s call them primitives. Let&rsquo;s now teach Julia how to differentiate operations involving these primitives. This would involve defining the adjoint for <code>sqrt</code> for a real number, for example.</p><p>$$ \frac{d{\sqrt{x}}}{d{x}} = \frac{1}{2\sqrt{x}} $$</p><p>Which can be expressed as</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#a6e22e>@adjoint</span> Base<span style=color:#f92672>.</span>sqrt(x<span style=color:#f92672>::</span><span style=color:#66d9ef>Real</span>) <span style=color:#f92672>=</span> Base<span style=color:#f92672>.</span>sqrt(x), Δ <span style=color:#f92672>-&gt;</span> ( Δ <span style=color:#f92672>*</span> inv(<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> sqrt(x)),)
</span></span></code></pre></div><p><em>The process and intuition to writing appropriate adjoints is a different blog.</em></p><p>If one could keep track of higher level operations, and define the adjoints on the primitives, we can essentially &ldquo;solve back&rdquo;, accumulating the resulting gradients from all the transforms (with the help of the adjoints from the primitives), and maintaining some structures, like constructing <code>NamedTuple</code>s with the appropriate keys, we can express any operation as differentiable. The backwards pass flow would basically go something like <strong>f3 &ndash;> f2 &ndash;> operations_with_some_concrete_types</strong>. This way we can traverse our code (specifically, the <a href=https://en.wikipedia.org/wiki/Intermediate_representation>intermediate representation</a>), and generate the backwards passes on the fly.</p><p>The cool part about this approach is that if we were to define the adjoints for the primitives or the base functions of a programming language, we can get any arbitrary program to be differentiated, and even support custom types and packages, almost for free. Add in an ideal optimising compiler, and these backwards passes become efficient too!</p><p>To give an example, the forward pass can be thought of as the process of tying your shoelaces, and the backwards pass is when we untie them by pulling the two ends apart.</p><center><image src=https://media2.giphy.com/media/12BVJ0EMPkepG0/giphy.gif , align=center></center><p>For a lot of this to work as expected, though, it is pertinent that the base language on top of which this entire machinery is built, exposes meaningful expressions of its intermediate representation that can be used to infer the backwards passes on the fly, and this is precisely what Julia does, given its history of hackability. Flux takes this hackability, and runs with it to the point of making sure that the entire library is focussed on inviting people to its source code and in fact extending it with their own layers and definitions and optimisers and what have you. This is a tough ask, since it means anticipating which assumptions are safe, and which aren&rsquo;t, but it&rsquo;s defintely worth it, since it then allows users to gracefully add in complexity as required.</p><p>A post will be up later talking about implementing a differentiable programming solution and another explaining the guts of what makes Flux and Zygote tick.</p><h2 id=a-basic-optimisation-loop>A Basic Optimisation Loop
<a class=anchor href=#a-basic-optimisation-loop>#</a></h2><p>For now, let&rsquo;s start with the classic example of optimising a random array to a different random array. It&rsquo;s just to illustrate how a simple iterative optimisation loop is expressed in Flux.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>z <span style=color:#f92672>=</span> rand(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>z′ <span style=color:#f92672>=</span> rand(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>loss(x) <span style=color:#f92672>=</span> Flux<span style=color:#f92672>.</span>mse(z <span style=color:#f92672>*</span> x, z′ <span style=color:#f92672>*</span> x)
</span></span><span style=display:flex><span>opt <span style=color:#f92672>=</span> Momentum()
</span></span><span style=display:flex><span>ps <span style=color:#f92672>=</span> Params([z])  <span style=color:#75715e># z is an implicit parameter, and thus needs to be wrapped in the `Params` type.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>:</span><span style=color:#ae81ff>10</span><span style=color:#f92672>^</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>  x <span style=color:#f92672>=</span> rand(<span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>  gs <span style=color:#f92672>=</span> gradient(ps) <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    loss(x)
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>  Flux<span style=color:#f92672>.</span>Optimise<span style=color:#f92672>.</span>update!(opt, ps, gs)
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>z <span style=color:#f92672>≈</span> z′ <span style=color:#75715e># true</span>
</span></span></code></pre></div><p>And just like that, we have moved <code>z</code> close to <code>z′</code>!</p><h2 id=adapting-this-to-a-custom-type>Adapting this to a custom type
<a class=anchor href=#adapting-this-to-a-custom-type>#</a></h2><p>Now, let&rsquo;s express this in terms of our own custom <code>struct</code>. For simplicity&rsquo;s sake, I am going to keep the fields of the <code>struct</code> Arrays, but they could be anything really.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#66d9ef>import</span> Base<span style=color:#f92672>:</span> <span style=color:#f92672>+</span>, <span style=color:#f92672>-</span>, <span style=color:#f92672>*</span>, <span style=color:#f92672>/</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> Base<span style=color:#f92672>:</span> isapprox
</span></span><span style=display:flex><span><span style=color:#66d9ef>using</span> MacroTools<span style=color:#f92672>:</span> <span style=color:#a6e22e>@forward</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>mutable struct</span> <span style=color:#66d9ef>GG</span>{<span style=color:#66d9ef>T</span>}
</span></span><span style=display:flex><span>  a<span style=color:#f92672>::</span><span style=color:#66d9ef>T</span>
</span></span><span style=display:flex><span>  b<span style=color:#f92672>::</span><span style=color:#66d9ef>T</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>GG(a) <span style=color:#f92672>=</span> GG(a, a)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> op <span style=color:#66d9ef>in</span> (<span style=color:#f92672>:+</span>, <span style=color:#f92672>:*</span>, <span style=color:#f92672>:-</span>, <span style=color:#f92672>:/</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>@eval</span> <span style=color:#a6e22e>@inline</span> <span style=color:#f92672>$</span>(op)(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>, b<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>) <span style=color:#f92672>=</span> GG(broadcast(<span style=color:#f92672>$</span>op, a<span style=color:#f92672>.</span>a, b<span style=color:#f92672>.</span>a), 
</span></span><span style=display:flex><span>					broadcast(<span style=color:#f92672>$</span>op, a<span style=color:#f92672>.</span>b, b<span style=color:#f92672>.</span>b))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>@eval</span> <span style=color:#a6e22e>@inline</span> <span style=color:#f92672>$</span>(op)(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>, b) <span style=color:#f92672>=</span> GG(broadcast(<span style=color:#f92672>$</span>op, a<span style=color:#f92672>.</span>a, b), 
</span></span><span style=display:flex><span>				     broadcast(<span style=color:#f92672>$</span>op, a<span style=color:#f92672>.</span>b, b))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>@eval</span> <span style=color:#a6e22e>@inline</span> <span style=color:#f92672>$</span>(op)(b, a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>) <span style=color:#f92672>=</span> GG(broadcast(<span style=color:#f92672>$</span>op, a<span style=color:#f92672>.</span>a, b), 
</span></span><span style=display:flex><span>				     broadcast(<span style=color:#f92672>$</span>op, a<span style=color:#f92672>.</span>b, b))
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@forward</span> GG<span style=color:#f92672>.</span>a Base<span style=color:#f92672>.</span>size
</span></span></code></pre></div><p>Here, we&rsquo;ve declared the struct, and defined some basic operations on how to handle the struct and its interaction with other types. Notice how we make use of Julia&rsquo;s excellent <code>broadcast</code>ing infrastructure, and a bit of code interpolation to avoid repeating defitintions for all the operations we want to hold it to, <code>(:+, :*, :-, :/)</code> in this case. <code>@inline</code> also hints to the Julia compiler that these operations can be inlined easily, and it should try to do this optimisation if possible.</p><p>And just to hit the nail on the head, let&rsquo;s define some more primitives that could come in handy while optimisation. These are operations that a lot of folks would already be used to doing for mathematical compute, but we will extrapolate it to arbitrary structs, that don&rsquo;t immediately make sense to be &ldquo;optimisable&rdquo;, in a manner of speaking.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>Base<span style=color:#f92672>.</span>zero(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>) <span style=color:#f92672>=</span> GG(zero(a<span style=color:#f92672>.</span>a), zero(a<span style=color:#f92672>.</span>b))
</span></span><span style=display:flex><span>Base<span style=color:#f92672>.</span>length(<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>Base<span style=color:#f92672>.:^</span>(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>, i) <span style=color:#f92672>=</span> GG(a<span style=color:#f92672>.</span>a <span style=color:#f92672>.^</span> i, a<span style=color:#f92672>.</span>b <span style=color:#f92672>.^</span> i)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> Statistics<span style=color:#f92672>:</span> mean
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mean(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>) <span style=color:#f92672>=</span> mean(a<span style=color:#f92672>.</span>a) <span style=color:#f92672>+</span> mean(a<span style=color:#f92672>.</span>b)
</span></span><span style=display:flex><span>Base<span style=color:#f92672>.</span>sum(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>) <span style=color:#f92672>=</span> sum(a<span style=color:#f92672>.</span>a) <span style=color:#f92672>+</span> sum(a<span style=color:#f92672>.</span>b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Base<span style=color:#f92672>.</span>isapprox(a<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>{<span style=color:#66d9ef>T</span>}, b<span style=color:#f92672>::</span><span style=color:#66d9ef>GG</span>{<span style=color:#66d9ef>T</span>}) <span style=color:#66d9ef>where</span> <span style=color:#66d9ef>T</span> <span style=color:#f92672>=</span> all([isapprox(a<span style=color:#f92672>.</span>a, b<span style=color:#f92672>.</span>a), isapprox(a<span style=color:#f92672>.</span>b, b<span style=color:#f92672>.</span>b)])
</span></span></code></pre></div><p>One last thing that might be necessary to take advantage of Flux&rsquo;s optimisers is to teach it what to do with the <code>GG</code> struct. We can extend it to just call <code>update</code> on all the fields of the struct.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#66d9ef>function</span> Flux<span style=color:#f92672>.</span>Optimise<span style=color:#f92672>.</span>update!(opt, x<span style=color:#f92672>::</span><span style=color:#66d9ef>T</span>, gs, fs <span style=color:#f92672>=</span> fieldnames(T)) <span style=color:#66d9ef>where</span> {<span style=color:#66d9ef>T</span><span style=color:#f92672>&lt;:</span><span style=color:#66d9ef>GG</span>}
</span></span><span style=display:flex><span>  gs <span style=color:#f92672>=</span> gs<span style=color:#f92672>.</span>x
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> f <span style=color:#66d9ef>in</span> fs
</span></span><span style=display:flex><span>    Flux<span style=color:#f92672>.</span>Optimise<span style=color:#f92672>.</span>update!(opt, getfield(x,f), getfield(gs,f))
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span></code></pre></div><p>And with that, we should be ready to do our optimisation.</p><p>Let&rsquo;s define two instances of our <code>GG</code> struct that we&rsquo;d like to optimise.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>a <span style=color:#f92672>=</span> GG(rand(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>), rand(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span>b <span style=color:#f92672>=</span> GG(rand(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>), rand(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>))
</span></span></code></pre></div><p>And we will use the same <code>Momentum</code> optimiser and mean-squared-error loss.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>opt <span style=color:#f92672>=</span> Momentum()
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>:</span><span style=color:#ae81ff>10</span><span style=color:#f92672>^</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>  gs <span style=color:#f92672>=</span> gradient(a) <span style=color:#66d9ef>do</span> x
</span></span><span style=display:flex><span>    sum((x<span style=color:#f92672>-</span>b) <span style=color:#f92672>*</span> (x<span style=color:#f92672>-</span>b)) <span style=color:#f92672>/</span> prod(size(x))
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>  Flux<span style=color:#f92672>.</span>Optimise<span style=color:#f92672>.</span>update!(opt, a, gs[<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>a <span style=color:#f92672>≈</span> b <span style=color:#75715e># true</span>
</span></span></code></pre></div><p>With this we have optimised a struct to another. Now we can take this concept and apply it to struct than a simple random array.</p><p>Another thing to note here is the complete lack of need of any call to <code>Params</code> in this case. This is because all of our parameters have been made explicit via passing <code>a</code>.</p><p>To give some context on the discussion earlier; the operations such as <code>sum</code>, <code>prod</code>, <code>size</code>, <code>-</code> etc are visible to Flux as valid operators to the parameters (<code>a</code>) and it looks into the implementation that we use for these transforms, to come up with valid <code>adjoint</code> methods. Think of it as the pulling motion from the shoelace example. Using these, it accumulates the gradients from all the operations, and finally returns them, keeping the structure of the paramters intact. This allows us to treat them as instances of the same type as usual, and finally optimise on them.</p><h2 id=optimising-colours>Optimising Colours
<a class=anchor href=#optimising-colours>#</a></h2><p>With the example done, let&rsquo;s try optimising colours. This is going to get fun! This example is taken from some of our work in the differentiable programming examples that we present <a href=https://github.com/MikeInnes/zygote-paper/blob/master/5_optimising_colours/run_colours.jl>here</a>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>target <span style=color:#f92672>=</span> RGB(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>colour <span style=color:#f92672>=</span> RGB(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>function</span> update_colour(c, Δ, η <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>return</span> RGB(
</span></span><span style=display:flex><span>        c<span style=color:#f92672>.</span>r <span style=color:#f92672>-</span> η<span style=color:#f92672>*</span>Δ<span style=color:#f92672>.</span>r,
</span></span><span style=display:flex><span>        c<span style=color:#f92672>.</span>g <span style=color:#f92672>-</span> η<span style=color:#f92672>*</span>Δ<span style=color:#f92672>.</span>g,
</span></span><span style=display:flex><span>        c<span style=color:#f92672>.</span>b <span style=color:#f92672>-</span> η<span style=color:#f92672>*</span>Δ<span style=color:#f92672>.</span>b,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> idx <span style=color:#66d9ef>in</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>:</span><span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>global</span> colour, target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Calculate gradients</span>
</span></span><span style=display:flex><span>    grads <span style=color:#f92672>=</span> Zygote<span style=color:#f92672>.</span>gradient(colour) <span style=color:#66d9ef>do</span> y
</span></span><span style=display:flex><span>        colordiff(target, y)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Update colour</span>
</span></span><span style=display:flex><span>    colour <span style=color:#f92672>=</span> update_colour(colour, grads[<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> idx <span style=color:#f92672>%</span> <span style=color:#ae81ff>5</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        <span style=color:#a6e22e>@info</span> idx, colour
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span></code></pre></div><p>Here our struct is just the <code>RGB</code> taken from the Colors.jl package. Again, the trick is to have meaningful operations defined on our type, based on the operations we will hit while calculating our loss function. The function <code>colordiff</code> already gives us the distance between two colours. It is important to note that the <code>Descent</code> optimiser does not check for convergence bounds and will ultimately diverge if the optimisation loop is not stopped.</p><p>I hope this helped motivate the different aspects of making a piece of code differentiable, and how that might be useful. The implementation need not be very complicated, if we understand the basic requirements for a library like Zygote. With the coming of <a href=https://github.com/FluxML/Optimisers.jl>Optimisers.jl</a> it should be possible to automate the optimisation over structs for many cases.</p><p><em>Cheers</em></p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#how-the-adjoints-are-defined>How the adjoints are defined</a></li><li><a href=#a-basic-optimisation-loop>A Basic Optimisation Loop</a></li><li><a href=#adapting-this-to-a-custom-type>Adapting this to a custom type</a></li><li><a href=#optimising-colours>Optimising Colours</a></li></ul></nav></div></aside></main></body></html>